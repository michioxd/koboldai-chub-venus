{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# KoboldAI for Chub Venus on Google Colab\n",
        "\n",
        "By [michioxd](https://github.com/michioxd)\n",
        "\n",
        "## Usage\n",
        "\n",
        "### Browser setup\n",
        "\n",
        "Because the CORS very stupid so we need disable them in Chromium (Chrome and another Chromium-based is fine but still recommend Chromium)\n",
        "\n",
        "[Download Chromium](https://chromium.woolyss.com)\n",
        "\n",
        "Linux:\n",
        "```shell\n",
        "chromium-browser --disable-web-security --user-data-dir=\"[some directory here]\"\n",
        "```\n",
        "\n",
        "Windows:\n",
        "- Right click to Chromium shortcut > Properties\n",
        "- At Target, add this:\n",
        "\n",
        "```powershell\n",
        " --disable-web-security --user-data-dir=\"[some directory here]\"\n",
        "```\n",
        "\n",
        "It should be look like this:\n",
        "\n",
        "```powershell\n",
        "C:\\Users\\Administrator\\AppData\\Local\\Chromium\\Application\\chrome.exe --disable-web-security --user-data-dir=\"[some directory here]\"\n",
        "```\n",
        "\n",
        "Remember to change [some directory here] to another directory.\n",
        "\n",
        "Like:\n",
        "\n",
        "```\n",
        "C:\\Users\\<yourusername>\\ChromiumData\n",
        "or\n",
        "/home/<yourusername>/ChromiumData\n",
        "```\n",
        "\n",
        "### Cloudflare Tunnels Setup\n",
        "\n",
        "- Go to [Zero Trust](https://one.dash.cloudflare.com)\n",
        "- In sidebar, click Access > Tunnels\n",
        "- Click Create a tunnel\n",
        "- Name your tunel, then click Next\n",
        "- Copy token (random string) from installation guide:\n",
        "```shell\n",
        "sudo cloudflared service install <TOKEN>\n",
        "```\n",
        "- Paste to cfToken\n",
        "- Click next \n",
        "- Public hostname:\n",
        "\n",
        "  Choose a domain (and subdomain if you want)\n",
        "\n",
        "  **Remember:** Path must be empty\n",
        "\n",
        "- Service section:\n",
        "\n",
        "  **Type**: HTTP\n",
        "\n",
        "  **URL**: `127.0.0.1:5000`\n",
        "\n",
        "- Click Save tunnel\n",
        "\n",
        "### Google Colab\n",
        "\n",
        "Click in the given order\n",
        "\n",
        "### Chub Venus setup\n",
        "\n",
        "Remember to run Chub Venus in already disabled CORS browser\n",
        "\n",
        "- Go to API Settings (click hambuger dropdown button)\n",
        "- At API, select KoboldAI\n",
        "- KoboldAI API URL set to your public hostname\n",
        "- Click Check KoboldAI then click Save Settings\n",
        "\n",
        "## KoboldAI still run in Read Only mode\n",
        "\n",
        "- Go to your public hostname\n",
        "- Click to AI button\n",
        "- Select to another Modal, you can try (NFSW Models > Erebus 2.7B (NSFW))\n",
        "\n",
        "**PLEASE NOTE:** Google only give 15GB VRAM"
      ],
      "metadata": {
        "id": "IV6q3r_8s7n5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <-- Tap this if you play on Mobile { display-mode: \"form\" }\n",
        "%%html\n",
        "<b>Press play on the music player to keep the tab alive, then start KoboldAI below (Uses only 13MB of data)</b><br/>\n",
        "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "cuVUB5edtfNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Install\n",
        "!git clone https://github.com/henk717/KoboldAI\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb && dpkg -i ./cloudflared-linux-amd64.deb && apt install screen"
      ],
      "metadata": {
        "id": "XM43Q_KMTpUM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Install Cloudflare service - Remember paste your CF Token\n",
        "cfToken = \"\" #@param {type:\"string\"}\n",
        "!sudo cloudflared service uninstall && sudo cloudflared service install {cfToken}"
      ],
      "metadata": {
        "id": "gYys_FxCcG1N",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7233ad-ae26-4d87-94a5-7ee63aa42f03"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2023-06-07T03:21:58Z\u001b[0m \u001b[32mINF\u001b[0m Using SysV\n",
            "\u001b[90m2023-06-07T03:21:58Z\u001b[0m \u001b[32mINF\u001b[0m Linux service for cloudflared uninstalled successfully\n",
            "\u001b[90m2023-06-07T03:21:58Z\u001b[0m \u001b[32mINF\u001b[0m Using SysV\n",
            "\u001b[90m2023-06-07T03:21:58Z\u001b[0m \u001b[32mINF\u001b[0m Linux service for cloudflared installed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Run this to start Cloudflare session\n",
        "!screen -dmS my_session cloudflared tunnel --url http://127.0.0.1:5000"
      ],
      "metadata": {
        "id": "T9LpVecWWkxS",
        "cellView": "form"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [Optional] Run this to end Cloudflare session\n",
        "!screen -X -S my_session quit"
      ],
      "metadata": {
        "id": "nFwKww4-aJBc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsqRX0yvsHI1",
        "outputId": "b51d6d15-bf0a-4166-80f0-6a94a11f292c",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab Check: False, TPU: False\n",
            "\u001b[35mINIT      \u001b[0m | \u001b[32mOK        \u001b[0m | \u001b[35mKAI Horde Models\u001b[0m\n",
            "\u001b[1mINFO      \u001b[0m | \u001b[32m__main__\u001b[0m:\u001b[32m<module>\u001b[0m:\u001b[32m641\u001b[0m - \u001b[1mWe loaded the following model backends: \n",
            "GooseAI\n",
            "Huggingface MTJ\n",
            "KoboldAI API\n",
            "Huggingface\n",
            "KoboldAI Old Colab Method\n",
            "Horde\n",
            "OpenAI\n",
            "Read Only\u001b[0m\n",
            "\u001b[1mINFO      \u001b[0m | \u001b[32m__main__\u001b[0m:\u001b[32mgeneral_startup\u001b[0m:\u001b[32m1356\u001b[0m - \u001b[1mRunning on Repo: https://github.com/henk717/KoboldAI Branch: united\u001b[0m\n",
            "\u001b[35mINIT      \u001b[0m | \u001b[37mStarting  \u001b[0m | \u001b[35mFlask\u001b[0m\n",
            "\u001b[35mINIT      \u001b[0m | \u001b[32mOK        \u001b[0m | \u001b[35mFlask\u001b[0m\n",
            "\u001b[35mINIT      \u001b[0m | \u001b[37mStarting  \u001b[0m | \u001b[35mWebserver\u001b[0m\n",
            "\u001b[35mINIT      \u001b[0m | \u001b[32mOK        \u001b[0m | \u001b[35mWebserver\u001b[0m\n",
            "\u001b[32mMESSAGE   \u001b[0m | \u001b[32mWebserver started! You may now connect with a browser at http://127.0.0.1:5000\u001b[0m\n",
            "\u001b[35mINIT      \u001b[0m | \u001b[37mSearching \u001b[0m | \u001b[35mGPU support\u001b[0m\n",
            "\u001b[35mINIT      \u001b[0m | \u001b[32mFound     \u001b[0m | \u001b[35mGPU support\u001b[0m\n",
            "\u001b[35mINIT      \u001b[0m | \u001b[37mStarting  \u001b[0m | \u001b[35mLUA bridge\u001b[0m\n",
            "\u001b[35mINIT      \u001b[0m | \u001b[32mOK        \u001b[0m | \u001b[35mLUA bridge\u001b[0m\n",
            "\u001b[35mINIT      \u001b[0m | \u001b[37mStarting  \u001b[0m | \u001b[35mLUA Scripts\u001b[0m\n",
            "\u001b[35mINIT      \u001b[0m | \u001b[32mOK        \u001b[0m | \u001b[35mLUA Scripts\u001b[0m\n",
            "Setting Seed\n",
            "Connection Attempt: 127.0.0.1\n",
            "\u001b[1mINFO      \u001b[0m | \u001b[32m__main__\u001b[0m:\u001b[32mdo_connect\u001b[0m:\u001b[32m2565\u001b[0m - \u001b[1mClient connected! UI_1\u001b[0m\n",
            "\u001b[1mINFO      \u001b[0m | \u001b[32mmodeling.inference_models.hf\u001b[0m:\u001b[32mset_input_parameters\u001b[0m:\u001b[32m191\u001b[0m - \u001b[1m{'0_Layers': 32, 'CPU_Layers': 0, 'Disk_Layers': 0, 'class': 'model', 'label': 'Erebus 2.7B (NSFW)', 'id': 'KoboldAI/OPT-2.7B-Erebus', 'name': 'KoboldAI/OPT-2.7B-Erebus', 'size': '8GB', 'ismenu': 'false', 'isdownloaded': 'true', 'isdirectory': 'false', 'menu': 'nsfwlist', 'plugin': 'Huggingface'}\u001b[0m\n",
            "\u001b[35mINIT      \u001b[0m | \u001b[37mSearching \u001b[0m | \u001b[35mGPU support\u001b[0m\n",
            "\u001b[35mINIT      \u001b[0m | \u001b[32mFound     \u001b[0m | \u001b[35mGPU support\u001b[0m\n",
            "\u001b[35mINIT      \u001b[0m | \u001b[32mInfo      \u001b[0m | \u001b[35mFinal device configuration:\u001b[0m\n",
            "\u001b[93m       DEVICE ID  |  LAYERS  |  DEVICE NAME\u001b[0m\n",
            "\u001b[0m               0  \u001b[93m|\u001b[0m      32  \u001b[93m|\u001b[0m  Tesla T4\u001b[0m\n",
            "\u001b[0m             N/A  \u001b[93m|\u001b[0m       0  \u001b[93m|\u001b[0m  (Disk cache)\u001b[0m\n",
            "\u001b[0m             N/A  \u001b[93m|\u001b[0m       0  \u001b[93m|\u001b[0m  (CPU)\u001b[0m\n",
            "\n",
            "Loading model tensors:   0%|          | 0/517 [00:00<?, ?it/s]/content/KoboldAI/modeling/lazy_loader.py:149: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  storage = STORAGE_TYPE_MAP[dtype].from_buffer(f.read(nbytes), \"little\")\n",
            "Loading model tensors:  48%|####7     | 246/517 [00:20<00:18, 14.52it/s]"
          ]
        }
      ],
      "source": [
        "#@title 4. Start\n",
        "!cd KoboldAI && ./play.sh"
      ]
    }
  ]
}